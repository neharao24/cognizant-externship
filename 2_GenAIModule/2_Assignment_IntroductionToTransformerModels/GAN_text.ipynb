{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/neharao/Downloads/Cognizant_Externship/cognizant-externship/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Device set to use mps:0\n",
      "Truncation was not explicitly activated but `max_length` is provided a specific value, please use `truncation=True` to explicitly truncate examples to max length. Defaulting to 'longest_first' truncation strategy. If you encode pairs of sequences (GLUE-style) with the tokenizer you can select this strategy more precisely by providing a specific strategy to `truncation`.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== GPT-2 Text Generation Experiments ===\n",
      "\n",
      "1. Education Prompt:\n",
      "Prompt: In the future, education will\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: In the future, education will also be a priority for employers to improve their workforce, as we can see in the way that the average wage for a full-time teacher in the US is $15.14 per hour.\n",
      "\n",
      "These changes are not new: the United States has seen some notable changes in recent years, along with a small number of new industries. However, these changes are not going to be reflected in the current job market.\n",
      "\n",
      "In a nutshell, the current state of the workforce represents a significant change, and it will be beneficial to the most talented workers. It is important to note that the current system does not directly address the needs of job seekers, but rather simply makes it harder for them to gain a foothold in a new career.\n",
      "\n",
      "In order to combat these factors, we are looking to introduce a new policy called \"Hire America.\"\n",
      "\n",
      "This policy was first introduced in 1999, as part of the Federal Employment Standards Act (FESA), which was designed to ensure that all workers eligible for a promotion and promotion benefit from a standard of living that is well below the poverty line.\n",
      "\n",
      "The new policy sets out a new minimum wage for a full-time teacher, and it is now in place to provide paid sick days to all new hires.\n",
      "\n",
      "\n",
      "2. News Headline Prompt:\n",
      "Prompt: Breaking News: The species of\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: Breaking News: The species of fish that live in the ocean are actually the same species that live in the sea.\n",
      "\n",
      "The fish are not directly related to the sea, but they are important for the survival of the marine ecosystems that support them.\n",
      "\n",
      "\"The fish are not directly related to the sea, but they are important for the survival of the marine ecosystems that support them,\" said Dr. Dario Pizzi, a marine biologist at the University of California, Berkeley. \"But there are some species that are quite different from the sea, and they are not related to the sea.\"\n",
      "\n",
      "The researchers found that the fish that live in the ocean are actually the same species that live in the sea.\n",
      "\n",
      "\"We found that the fish that live in the ocean are actually the same species that live in the sea,\" said Dr. Dario Pizzi.\n",
      "\n",
      "\"They are actually the same species that live in the ocean,\" said Dr. Dario Pizzi.\n",
      "\n",
      "The researchers also found that the fish that live in the ocean are actually the same species that live in the sea.\n",
      "\n",
      "\"We found that the fish that live in the ocean are actually the same species that live in the sea,\" said Dr. Dario Pizzi.\n",
      "\n",
      "\n",
      "\n",
      "3. Short Story Opener Prompt:\n",
      "Prompt: Once upon a time, there was\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: Once upon a time, there was no doubt about it.\n",
      "\n",
      "The next day, the first of the four-day-long talks began. The government gave a final ultimatum to the opposition: if the government didn't agree to a deal, it would not let the opposition hold the government at this stage.\n",
      "\n",
      "On March 5, the government announced that it would allow the opposition to take control of the country's parliament, the National Assembly, and allow the opposition to become the government's main political bloc.\n",
      "\n",
      "The opposition was already a powerful force in the country's political system: the United States and Russia are the world's top allies. The United States supported President Reagan's first term in office, as well as the Bush administration.\n",
      "\n",
      "The U.S.-backed regime won the elections, but the U.S. government was not the only party who supported the opposition.\n",
      "\n",
      "The U.S.-backed regime won the elections, but the U.S. government was not the only party who supported the opposition.\n",
      "\n",
      "On March 20, the U.S.-backed regime won the election, but the U.S. government was not the only party who supported the opposition.\n",
      "\n",
      "On March 20, the U.S.-backed regime won the election\n",
      "\n",
      "4. Dialogue Prompt:\n",
      "Prompt: \"Hi Joana! I didn't expect you here\" Fred said. She replied,\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: \"Hi Joana! I didn't expect you here\" Fred said. She replied, \"I'm sure I will\" she replied with a grin. \"You are welcome to come over, darling\" Fred said, sitting on the bed and leaning over her, \"And how about an evening of dancing\" Fred smiled, saying, \"I'll see you then, darling\" she said with a kiss of her hands. She was about to go to bed when she was startled by something. She noticed something while she was trying to get dressed. They were both naked and very hot and very beautiful. Both of them seemed to be pretty. \"What a beautiful morning\" Fred said, kissing her on the cheeks. \"No problem, beautiful\" she said, \"let do your thing\" Fred kissed her back and started working, getting into the most sexy position imaginable, he pulled her in at a 30 C rating. Her fingers were so big, they were so big it took her all day to finish them. Then her fingers were pulled down to her bare fingers and her fingers would be hard enough to see but her fingernails were so hard and the skin was so hard. \"Oh darling\" she said as she tried to open her mouth, but she could not see her tongue with her naked lips. \"Oh darling\" she said as she closed her\n",
      "\n",
      "5. Question Prompt:\n",
      "Prompt: Which country has the largest population?\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=30) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generated: Which country has the largest population?\n",
      "\n",
      "The United States:\n",
      "\n",
      "Population: 1.1 million\n",
      "\n",
      "Population density: 2,000 people per square mile\n",
      "\n",
      "Population density index: 100.0\n",
      "\n",
      "Population density index next to 100 is 2000-1999.\n",
      "\n",
      "What is the cost of living in this city?\n",
      "\n",
      "The cost of living in this city is about $1,000 in 2014. That's about $1,000 less than the average cost of living in this city.\n",
      "\n",
      "What is the median household income in this city?\n",
      "\n",
      "The median household income in this city is $37,000. That's about $37,000 less than the average household income in this city.\n",
      "\n",
      "What is the median household income in this city?\n",
      "\n",
      "The median household income in this city is $44,000. That's about $44,000 less than the average household income in this city.\n",
      "\n",
      "What is the median household income in this city?\n",
      "\n",
      "The median household income in this city is $59,000. That's about $59,000 less than the average household income in this city.\n",
      "\n",
      "What is the median household income in this city?\n",
      "\n",
      "The median household income in this city is $91,000. That\n",
      "\n",
      "6. Max Length:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=120) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Short (30 tokens): Music is important because it's where the music is heard. It's where you've got the information to know to make the decision, and I think that's what drives the music and the content. It's also where the music comes from.\"\n",
      "\n",
      "\"We're all about the music. The music comes from the listeners, the music comes from the users, the music comes from the artist, the music comes from the audience.\"\n",
      "\n",
      "\"We're all about the music. The music comes from the listeners, the music comes from the users, the music comes from the audience.\"\n",
      "\n",
      "The Music of the Week is a series of shows on BBC Radio 5 Live on Saturdays and Sundays.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Long (120 tokens): Music is important because it can make people go to work in other places. I'm sure people will say 'Oh, you're not doing this for money.' And I tell them, 'Well, you're doing it because you can, because it's good for you.'\"\n",
      "\n",
      "Sitting at the back of the room, the two talked about it for a couple of minutes before he spoke about the team's growth in the U.S. and the national anthem. In that moment, the team's coach, coach for the past seven years, and a lot of people will say, 'No, I don't think so.' He's right. But the fact is, when I was in college, I didn't play that way. I didn't think I was going to play that way. I thought it was too much of a burden.\n",
      "\n",
      "\"I was a big fan of the anthem and the country. I was proud of the way we played, and I like the way we played, and I think it was good for the country. I think it's important to the country. It's an important event, and they need to remember that. But the fact is, no matter what we're doing, we're always going to be better. And that's why\n",
      "\n",
      "7. Temperature:\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Low Temperature (0.2): Dogs help humanity by keeping them from dying.\n",
      "\n",
      "The dogs are also used to help humans with their own problems.\n",
      "\n",
      "The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems. The dogs are also used to help humans with their own problems.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n",
      "Both `max_new_tokens` (=256) and `max_length`(=60) seem to have been set. `max_new_tokens` will take precedence. Please refer to the documentation for more information. (https://huggingface.co/docs/transformers/main/en/main_classes/text_generation)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "High Temperature (1.2): Dogs help humanity by enabling better reproduction, more offspring with mothers and offspring who can spend more time with the children, more freedom, and healthier lives — all the things that animals need to do for survival and prosperity, for their healthy, productive body needs... that animals need to fulfill to fulfill their humanity. How much more need and how much more should they satisfy the demands of our species at this moment in our lives? And that demand seems increasingly unmet. Yet in many ways it is also not that dire as it may initially appear.\n",
      "\n",
      "\n",
      "This time the situation for mankind (but not many) is much more dire. Humanity seems almost too hungry to feed itself. If its animals don't starve (this is especially not true in North America), then that of any nation, we most certainly would be \"hunger starved\". We would probably still have the money to fight over it, too.\n",
      "\n",
      "\n",
      "I don't know if many of you read this correctly. This situation for such an innocent species seems a bit absurd, and one that seems to have no self-interest whatsoever, yet the idea that it will have more time to fulfill its human needs is almost certain to raise the very question that is most important in this debate: will our nation succumb just as quickly to starvation and lack\n",
      "\n",
      "8. Multiple Outputs (same prompt, different results):\n",
      "Prompt: The main reason people like ice cream is\n",
      "Version 1: The main reason people like ice cream is to get your head around a lot of things. It's not about trying to impress people, it's about trying to get your head around some things. Not only do they get to see some things, they may have that experience too, but when you have to leave your room and go out of your way to get the best ice cream you can get for your family, it's a lot of work.\"\n",
      "\n",
      "He was joined by his mom, who said she was \"very happy\" with his decision. He said, \"My mom and I were super excited and we just wanted to take a shower, we were so excited we didn't want to do it with other kids because when we see somebody, when they get to the end of their period, we can see that it's not all bad.\"\n",
      "\n",
      "He said his friends are still not sure why he chose to get a divorce. \"We don't know why he didn't get married. Probably he wasn't happy with the way things are now,\" he said.\n",
      "\n",
      "One person who heard about the story shared it with him on Reddit.\n",
      "\n",
      "\"I think the main reason they thought they were doing this thing was because it was just too hard. The idea of getting a divorce was too difficult\n",
      "Version 2: The main reason people like ice cream is because it's ice cream. It's also ice cream flavored with maple syrup. That's what my mom used to call ice cream; ice cream flavored with maple syrup.\n",
      "\n",
      "A few years ago I was in school, and a friend of mine said \"I want to go to the local store, which is the Ice Cream Club. I would like to see a piece of ice cream in the corner, and would like to see what kind of ice cream it is.\" I told him, \"You can be a New York lawyer.\" After that I learned that the store had to make everything for kids so they would have a choice. This is what the Ice Cream Club is all about.\n",
      "\n",
      "A few years ago, I visited a kid who was very young at the time. In a conversation we had we said, \"We don't know how to produce the ice cream, but we know that is the most important part of the whole thing of that ice cream. A little bit of ice cream will do.\" He was very impressed, and asked, \"What would you like to see by now?\"\n",
      "\n",
      "He asked me if I would like to know what I would like the most about my ice cream. And I said, \"Oh, my God, I\n",
      "Version 3: The main reason people like ice cream is because of its unique flavors because it's a really good ice cream. It's not a cream that tastes bad. It's the best ice cream you will get.\n",
      "\n",
      "But what if you wanted to go to the bar instead of the ice cream vending machine?\n",
      "\n",
      "Well, you don't have to go to the bar for the ice cream, your ice cream will still be good.\n",
      "\n",
      "I feel like I'm trying to say something, but not really.\n",
      "\n",
      "Well, maybe that's why we're here.\n",
      "\n",
      "And just like when you're trying to catch a flight, you'll find that this vending machine has an interesting flavor.\n",
      "\n",
      "If that's the case, then why would you bother going to the bar when you have ice cream there?\n",
      "\n",
      "Maybe because I like ice cream a lot more than ice cream is.\n",
      "\n",
      "And why not?\n",
      "\n",
      "Because we have the greatest ice cream vending machines in the world.\n",
      "\n",
      "So yeah, I think that's why we're here.\n",
      "\n",
      "Thank you so much for stopping by.\n",
      "\n",
      "So after I go to the bar, do you think I should give you something special?\n",
      "\n",
      "Yes, of course, we're here because I'm excited about our future.\n",
      "\n",
      "=== End of Experiments ===\n"
     ]
    }
   ],
   "source": [
    "from transformers import pipeline\n",
    "import torch\n",
    "\n",
    "# Load GPT-2 text generation model\n",
    "generator = pipeline('text-generation', model='gpt2')\n",
    "\n",
    "print(\"=== GPT-2 Text Generation Experiments ===\\n\")\n",
    "\n",
    "\n",
    "# Adjusting Prompts --------------\n",
    "\n",
    "# Basic prompt\n",
    "print(\"1. Education Prompt:\")\n",
    "prompt = 'In the future, education will'\n",
    "print(f\"Prompt: {prompt}\")\n",
    "result = generator(prompt, max_length=60, temperature=0.7)\n",
    "print(f\"Generated: {result[0]['generated_text']}\\n\")\n",
    "\n",
    "# News headline\n",
    "print(\"2. News Headline Prompt:\")\n",
    "prompt = 'Breaking News: The species of'\n",
    "print(f\"Prompt: {prompt}\")\n",
    "result = generator(prompt, max_length=60, temperature=0.5)\n",
    "print(f\"Generated: {result[0]['generated_text']}\\n\")\n",
    "\n",
    "# Story opener\n",
    "print(\"3. Short Story Opener Prompt:\")\n",
    "prompt = 'Once upon a time, there was'\n",
    "print(f\"Prompt: {prompt}\")\n",
    "result = generator(prompt, max_length=60, temperature=0.6)\n",
    "print(f\"Generated: {result[0]['generated_text']}\\n\")\n",
    "\n",
    "# Dialogue\n",
    "print(\"4. Dialogue Prompt:\")\n",
    "prompt = '\"Hi Joana! I didn\\'t expect you here\" Fred said. She replied,'\n",
    "print(f\"Prompt: {prompt}\")\n",
    "result = generator(prompt, max_length=60, temperature=0.9)\n",
    "print(f\"Generated: {result[0]['generated_text']}\\n\")\n",
    "\n",
    "# Question\n",
    "print(\"5. Question Prompt:\")\n",
    "prompt = 'Which country has the largest population?'\n",
    "print(f\"Prompt: {prompt}\")\n",
    "result = generator(prompt, max_length=60, temperature=0.4)\n",
    "print(f\"Generated: {result[0]['generated_text']}\\n\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# Adjusting parameters --------------\n",
    "\n",
    "# Max Length\n",
    "print(\"6. Max Length:\")\n",
    "prompt = 'Music is important because'\n",
    "\n",
    "    # Short output\n",
    "result_short = generator(prompt, max_length=30, temperature=0.7)\n",
    "print(f\"Short (30 tokens): {result_short[0]['generated_text']}\")\n",
    "\n",
    "    # Long output\n",
    "result_long = generator(prompt, max_length=120, temperature=0.7)\n",
    "print(f\"Long (120 tokens): {result_long[0]['generated_text']}\\n\")\n",
    "\n",
    "\n",
    "# Temperature\n",
    "print(\"7. Temperature:\")\n",
    "prompt = 'Dogs help humanity by'\n",
    "\n",
    "    # Low temperature\n",
    "result_low = generator(prompt, max_length=60, temperature=0.2)\n",
    "print(f\"Low Temperature (0.2): {result_low[0]['generated_text']}\")\n",
    "\n",
    "    # High temperature\n",
    "result_high = generator(prompt, max_length=60, temperature=1.2)\n",
    "print(f\"High Temperature (1.2): {result_high[0]['generated_text']}\\n\")\n",
    "\n",
    "\n",
    "# Multiple outputs for same prompt\n",
    "print(\"8. Multiple Outputs (same prompt, different results):\")\n",
    "prompt = 'The main reason people like ice cream is'\n",
    "print(f\"Prompt: {prompt}\")\n",
    "results = generator(prompt, max_length=60, temperature=0.8, num_return_sequences=3)\n",
    "for i, result in enumerate(results):\n",
    "    print(f\"Version {i+1}: {result['generated_text']}\")\n",
    "print()\n",
    "\n",
    "\n",
    "\n",
    "print(\"=== End of Experiments ===\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
